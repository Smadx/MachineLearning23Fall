{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time as t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the real world, you cannot learn how the data was generated. So do not rely on this function when coding your lab.\n",
    "def generate_data(dim, num):\n",
    "    x = np.random.normal(0, 10, [num, dim])\n",
    "    coef = np.random.uniform(-1, 1, [dim, 1])\n",
    "    pred = np.dot(x, coef)\n",
    "    pred_n = (pred - np.mean(pred)) / np.sqrt(np.var(pred))\n",
    "    label = np.sign(pred_n)\n",
    "    mislabel_value = np.random.uniform(0, 1, num)\n",
    "    mislabel = 0\n",
    "    for i in range(num):\n",
    "        if np.abs(pred_n[i]) < 1 and mislabel_value[i] > 0.9 + 0.1 * np.abs(pred_n[i]):\n",
    "            label[i] *= -1\n",
    "            mislabel += 1\n",
    "    return x, label, mislabel/num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "x, y, mr = generate_data(5, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  2.13760666,   1.87454384,  -6.95997602,  13.97529007,\n",
       "          -0.51487694],\n",
       "        [-10.91257963,  -1.36220876,  -6.61320399,  -5.82544723,\n",
       "          15.90106451],\n",
       "        [ -4.00000957,  -5.27710355,   1.26506736,   2.39644677,\n",
       "          11.46462714],\n",
       "        [  6.66319978, -11.50620263, -11.80816857,  -5.85170807,\n",
       "           4.65032036],\n",
       "        [ 16.73316604,   5.39077602,   2.87937728,  10.96184704,\n",
       "           8.17381161]]),\n",
       " array([[ 1.],\n",
       "        [-1.],\n",
       "        [ 1.],\n",
       "        [-1.],\n",
       "        [ 1.]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5], y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write your model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying the overall structure is acceptable but not recommended\n",
    "class SVM1:\n",
    "    def __init__(self, dim, C=1.0):\n",
    "        \"\"\"\n",
    "        parameter:\n",
    "        - dim: 数据维度\n",
    "        - C: lagrange乘子的上界\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "        self.C = C\n",
    "        self.alpha = None # lagrange乘子\n",
    "        self.w = None # 分类超平面的法向量\n",
    "        self.b = 0\n",
    "    \n",
    "    def p(self, x):\n",
    "        \"\"\"\n",
    "        计算预测值\n",
    "        \"\"\"\n",
    "        return np.sign(self.w.dot(x) + self.b)\n",
    "\n",
    "    def fit(self, X, y, max_iter = 1000):\n",
    "        \"\"\"\n",
    "        Train SVM by SMO algorithm. \n",
    "\n",
    "        parameter:\n",
    "        - X: 训练数据\n",
    "        - y: 训练标签\n",
    "        - max_iter: 最大迭代次数\n",
    "        \"\"\"\n",
    "        m, n = X.shape\n",
    "        self.alpha = np.zeros(m)\n",
    "        self.w = np.zeros(n)\n",
    "        self.b = 0\n",
    "\n",
    "        for _ in range(max_iter):\n",
    "            for i in range(m):\n",
    "                # 计算预测值和误差\n",
    "                g_i = self.p(X[i])\n",
    "                E_i = g_i - y[i]\n",
    "\n",
    "                # KKT条件\n",
    "                if (y[i] * g_i - 1 < -1e-3 and self.alpha[i] < self.C) or \\\n",
    "                   (y[i] * g_i - 1 > 1e-3 and self.alpha[i] > 0):\n",
    "\n",
    "                    # 选择第二个变量 j\n",
    "                    j = self.select_second_variable(i, m)\n",
    "                    g_j = self.p(X[j])\n",
    "                    E_j = g_j - y[j]\n",
    "\n",
    "                    # 保存旧的alpha\n",
    "                    alpha_i_old, alpha_j_old = self.alpha[i], self.alpha[j]\n",
    "\n",
    "                    # 计算上下界L和H\n",
    "                    L, H = self.compute_L_H(y[i], y[j], alpha_i_old, alpha_j_old)\n",
    "\n",
    "                    # 如果L和H相等，则不进行更新\n",
    "                    if L == H:\n",
    "                        continue\n",
    "\n",
    "                    # 计算未经剪辑的新alpha_j\n",
    "                    eta = 2.0 * X[i].dot(X[j]) - X[i].dot(X[i]) - X[j].dot(X[j])\n",
    "                    if eta >= 0:\n",
    "                        continue\n",
    "\n",
    "                    # 计算新的未经剪辑的alpha_j\n",
    "                    self.alpha[j] = alpha_j_old - (y[j] * (E_i - E_j)) / eta\n",
    "\n",
    "                    # 剪辑alpha_j\n",
    "                    self.alpha[j] = np.clip(self.alpha[j], L, H)\n",
    "\n",
    "                    # 更新alpha_i\n",
    "                    self.alpha[i] = alpha_i_old + y[i] * y[j] * (alpha_j_old - self.alpha[j])\n",
    "\n",
    "                    # 更新阈值b\n",
    "                    b_i = self.b - E_i - y[i] * (self.alpha[i] - alpha_i_old) * X[i].dot(X[i]) \\\n",
    "                          - y[j] * (self.alpha[j] - alpha_j_old) * X[i].dot(X[j])\n",
    "                    b_j = self.b - E_j - y[i] * (self.alpha[i] - alpha_i_old) * X[i].dot(X[j]) \\\n",
    "                          - y[j] * (self.alpha[j] - alpha_j_old) * X[j].dot(X[j])\n",
    "                    if 0 < self.alpha[i] < self.C:\n",
    "                        self.b = b_i\n",
    "                    elif 0 < self.alpha[j] < self.C:\n",
    "                        self.b = b_j\n",
    "                    else:\n",
    "                        self.b = (b_i + b_j) / 2.0\n",
    "            # 更新w\n",
    "            self.w = np.zeros(n)\n",
    "            for i in range(m):\n",
    "                self.w += self.alpha[i] * y[i] * X[i]\n",
    "\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Generate prediction probabilities on a new\n",
    "        collection of data points by your model.\n",
    "        \"\"\"\n",
    "        # 计算预测值\n",
    "        pred = []\n",
    "        for x in X:\n",
    "            pred.append(self.p(x))\n",
    "        return np.array(pred)\n",
    "\n",
    "    \n",
    "    def kernel(self, X1, X2):\n",
    "        \"\"\"\n",
    "        Compute the kernel between two matrices.\n",
    "        \"\"\"\n",
    "        return np.dot(X1, X2.T)\n",
    "\n",
    "    def select_second_variable(self, i, m):\n",
    "        \"\"\"\n",
    "        Select the second variable alpha_j.\n",
    "        \"\"\"\n",
    "        j = i\n",
    "        while j == i:\n",
    "            j = np.random.randint(0, m)\n",
    "        return j\n",
    "\n",
    "    def compute_L_H(self, y_i, y_j, alpha_i_old, alpha_j_old):\n",
    "        \"\"\"\n",
    "        Compute the lower and upper bounds for alpha_j.\n",
    "        \"\"\"\n",
    "        if y_i != y_j:\n",
    "            L = max(0, alpha_j_old - alpha_i_old)\n",
    "            H = min(self.C, self.C + alpha_j_old - alpha_i_old)\n",
    "        else:\n",
    "            L = max(0, alpha_i_old + alpha_j_old - self.C)\n",
    "            H = min(self.C, alpha_i_old + alpha_j_old)\n",
    "        return L, H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "class SVM2:\n",
    "    def __init__(self, dim, lr=0.01, gamma=0.1, max_iter=1000, tol=1e-3, batch_size=16, epochs=10):\n",
    "        \"\"\"\n",
    "        parameter:\n",
    "        - dim: 数据维度\n",
    "        - lr: 学习率\n",
    "        - gamma: 正则化系数\n",
    "        - max_iter: 最大迭代次数\n",
    "        - tol: 容忍度\n",
    "        - batch_size: 每个batch的大小\n",
    "        - epochs: 训练的总轮数\n",
    "        \"\"\"\n",
    "        self.lr = lr\n",
    "        self.gamma = gamma\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.w = None # 分类超平面的法向量\n",
    "        self.b = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def p(self, x):\n",
    "        \"\"\"\n",
    "        计算预测值\n",
    "        \"\"\"\n",
    "        return np.sign(self.w.dot(x) + self.b)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the SVM by gradient descent\n",
    "        \"\"\"\n",
    "        m, n = X.shape\n",
    "        self.w = np.zeros(n)\n",
    "        loss = []\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            for batch_start in tqdm(range(0, m, self.batch_size)):\n",
    "                batch_end = min(batch_start + self.batch_size, m)\n",
    "                X_batch, y_batch = X[batch_start:batch_end], y[batch_start:batch_end]\n",
    "\n",
    "                for _ in range(self.max_iter):\n",
    "                    gradient_w, gradient_b, l = self.grad(X_batch, y_batch)\n",
    "\n",
    "                    # 更新参数\n",
    "                    self.w -= self.lr * gradient_w\n",
    "                    self.b -= self.lr * gradient_b\n",
    "\n",
    "                    loss.append(l)\n",
    "\n",
    "                    # 检查是否收敛\n",
    "                    if np.linalg.norm(gradient_w) < self.tol:\n",
    "                        break\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def grad(self, X, y):\n",
    "        loss = 0\n",
    "        grad_w = 0\n",
    "        grad_b = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            z = y[i] * (self.p(X[i])) - 1\n",
    "            if 1 - z > 0:\n",
    "                loss += 1 - z\n",
    "                grad_w += -y[i] * X[i]\n",
    "                grad_b += -y[i]\n",
    "            \n",
    "        loss += self.gamma * np.linalg.norm(self.w, ord=2) * np.linalg.norm(self.w, ord=2)\n",
    "        grad_w += self.gamma * 2 * self.w / X.shape[0]\n",
    "\n",
    "        return grad_w, grad_b, loss\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        A same predict function with SVM1 is acceptable.\n",
    "        \"\"\"\n",
    "        # 计算预测值\n",
    "        pred = []\n",
    "        for x in X:\n",
    "            pred.append(self.p(x))\n",
    "        return np.array(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# construct and train your models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mislabel rate:  0.0351\n"
     ]
    }
   ],
   "source": [
    "# generate data\n",
    "X_data, y_data, mislabel = generate_data(20, 10000) \n",
    "\n",
    "# split data\n",
    "X_train = X_data[:8000]\n",
    "y_train = y_data[:8000]\n",
    "X_test = X_data[8000:]\n",
    "y_test = y_data[8000:]\n",
    "\n",
    "print(\"Mislabel rate: \", mislabel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM1 time: 120.04548382759094\n"
     ]
    }
   ],
   "source": [
    "# constrcut model and train (remember to record your time consumption)\n",
    "model1 = SVM1(20,10)\n",
    "start = t.time()\n",
    "model1.fit(X_train, y_train)\n",
    "end = t.time()\n",
    "print(\"SVM1 time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:23<00:00, 21.62it/s]\n",
      "100%|██████████| 500/500 [00:23<00:00, 21.52it/s]\n",
      "100%|██████████| 500/500 [00:23<00:00, 21.69it/s]\n",
      "100%|██████████| 500/500 [00:23<00:00, 21.33it/s]\n",
      "100%|██████████| 500/500 [00:23<00:00, 21.44it/s]\n",
      "100%|██████████| 500/500 [00:23<00:00, 21.24it/s]\n",
      "100%|██████████| 500/500 [00:23<00:00, 21.31it/s]\n",
      "100%|██████████| 500/500 [00:23<00:00, 21.18it/s]\n",
      "100%|██████████| 500/500 [00:23<00:00, 21.38it/s]\n",
      "100%|██████████| 500/500 [00:23<00:00, 21.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM2 time: 233.70003581047058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = SVM2(20,0.001,0.01,200,1e-3,16,10)\n",
    "start = t.time()\n",
    "loss = model2.fit(X_train, y_train)\n",
    "end = t.time()\n",
    "print(\"SVM2 time:\", end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict and compare your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM3 time: 19.82708239555359\n"
     ]
    }
   ],
   "source": [
    "import sklearn.svm as svm\n",
    "model3 = svm.SVC(kernel='linear')\n",
    "start = t.time()\n",
    "model3.fit(X_train, y_train)\n",
    "end = t.time()\n",
    "print(\"SVM3 time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc_1: 0.914\n",
      "Acc_2: 0.941\n",
      "Acc_3: 0.952\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "pred_1 = model1.predict(X_test)\n",
    "pred_2 = model2.predict(X_test)\n",
    "pred_3 = model3.predict(X_test)\n",
    "acc_1 = 0\n",
    "acc_2 = 0\n",
    "acc_3 = 0\n",
    "\n",
    "# compare with generated label\n",
    "for i in range(y_test.shape[0]):\n",
    "    if pred_1[i] == y_test[i]:\n",
    "        acc_1 += 1\n",
    "    if pred_2[i] == y_test[i]:\n",
    "        acc_2 += 1\n",
    "    if pred_3[i] == y_test[i]:\n",
    "        acc_3 += 1\n",
    "        \n",
    "# # compare each method\n",
    "print(\"Acc_1:\", acc_1 / y_test.shape[0])\n",
    "print(\"Acc_2:\", acc_2 / y_test.shape[0])\n",
    "print(\"Acc_3:\", acc_3 / y_test.shape[0])\n",
    "\n",
    "\n",
    "# (Optional) compare with sklearn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
